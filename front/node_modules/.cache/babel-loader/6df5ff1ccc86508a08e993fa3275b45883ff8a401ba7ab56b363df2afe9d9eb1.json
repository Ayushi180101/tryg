{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\PC\\\\tryg\\\\front\\\\src\\\\App.js\";\nimport React from 'react';\nimport ScraperForm from './components/ScraperForm';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction App() {\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: /*#__PURE__*/_jsxDEV(ScraperForm, {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 7,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 6,\n    columnNumber: 5\n  }, this);\n}\n_c = App;\nexport default App;\n\n// this is the frontend code:\n\n// import React, { useState, useRef} from 'react';\n// import axios from 'axios';\n// import './form.css';\n// import * as html2pdf from 'html2pdf.js';\n\n// const ProgressBar = ({ activeFieldset }) => (\n//     <ul id=\"progressbar\">\n//       <li className={activeFieldset === 1 ? 'active' : ''}>URL EXTRACTION</li>\n//       <li className={activeFieldset === 2 ? 'active' : ''}>EXTRACTED URLS</li>\n//       <li className={activeFieldset === 3 ? 'active' : ''}>SCRAPING</li>\n//       <li className={activeFieldset === 4 ? 'active' : ''}>EXTRACTED DATA</li>\n//     </ul>\n//   );\n\n//   const Fieldset = ({ title, subtitle, children, style }) => (\n//     <fieldset style={style}>\n//       <h2 className=\"fs-title\">{title}</h2>\n//       <h3 className=\"fs-subtitle\">{subtitle}</h3>\n//       {children}\n//     </fieldset>\n//   );\n\n// const ScraperForm = () => {\n\n//     const [activeFieldset, setActiveFieldset] = useState(1);\n//     const [formData, setFormData] = useState({\n//       email: '',\n//       text2: '',\n//       text3: '',\n//     });\n\n//   const [urls, setUrls] = useState('');\n//   const [selectors, setSelectors] = useState('');\n//   const [output, setOutput] = useState('');\n//   const [showUrlWarning, setShowUrlWarning] = useState(false);\n\n//   const [generatedUrls, setGeneratedUrls] = useState('');\n\n//   const preRef = useRef(null);\n\n//   const isUrlValid = (userInput) => {\n//     const res = userInput.match(/(http(s)?:\\/\\/.)?(www\\.)?[-a-zA-Z0-9@:%._+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_+.~#?&//=]*)/g);\n//     return res !== null;\n//   };\n\n//   const handleDownloadPDF = () => {\n//     const element = preRef.current; \n//     const pdfOptions = {\n//       margin: 10,\n//       filename: 'output.pdf',\n//       image: { type: 'jpeg', quality: 0.98 },\n//       html2canvas: { scale: 2 },\n//       jsPDF: { unit: 'mm', format: 'a4', orientation: 'portrait' },\n//     };\n\n//     html2pdf(element, pdfOptions);\n//   };\n\n//   const downloadPDF = async () => {\n//     const element1 = preRef.current; \n//     const pdfOptions1 = {\n//       margin: 10,\n//       filename: 'list.pdf',\n//       image: { type: 'jpeg', quality: 0.98 },\n//       html2canvas: { scale: 2 },\n//       jsPDF: { unit: 'mm', format: 'a4', orientation: 'portrait' },\n//     };\n\n//     html2pdf(element1, pdfOptions1);\n//   };\n\n//   const handleStart = async (e) => {\n//     e.preventDefault();\n\n//     try {\n//       const response = await axios.post('http://localhost:5045/scraper', { url: formData.email });\n//       setGeneratedUrls(response.data.urlContent || '');\n\n//       handleNext();\n//     } catch (error) {\n//       console.error('Error generating list of URLs:', error);\n//     }\n//   };\n\n//   const handleInputChange = (e) => {\n//     const { name, value } = e.target;\n\n//     if (name === 'email') {\n//       setShowUrlWarning(!isUrlValid(value));\n\n//     }\n\n//     setFormData((prevData) => ({\n//         ...prevData,\n//         [name]: value,\n//       }));\n\n//   };\n\n//   const handleNext = () => {\n//     setActiveFieldset((prevActiveFieldset) => prevActiveFieldset + 1);\n//   };\n\n//   const handlePrevious = () => {\n//     setActiveFieldset((prevActiveFieldset) => prevActiveFieldset - 1);\n//   };\n\n//   const handleSubmit2 = async (e) => {\n//     e.preventDefault();\n\n//     try {\n//       const response = await axios.post('http://localhost:5045/scrape', {\n//         urls: urls.split(',').map((url) => url.trim()),\n//         selectors: selectors.split(',').map((selector) => selector.trim()),\n//       }, {\n//         timeout: 5000, \n//       });\n\n//       console.log(response.data + '\\n');\n\n//       setOutput(response.data.tableString);\n//       handleNext();\n\n//     } catch (error) {\n//       console.error('Error:', error);\n//     }\n\n//   };\n\n//   return (\n\n//   <div>\n//     <ProgressBar activeFieldset={activeFieldset} />\n//       <form id=\"msform\" onSubmit={handleSubmit2}>\n\n//         <Fieldset style={{ display: activeFieldset === 1 ? 'block' : 'none' }}>\n//         <h2 className=\"fs-title\">Provide the Main URL</h2>\n//  \t\t    <h3 className=\"fs-subtitle\">This step will provide the list of all URLS</h3>\n//              <input\n//           type=\"text\"\n//           name=\"email\"\n//           placeholder=\"Main URL\"\n//           value={formData.email}\n//           onChange={handleInputChange}\n//         />\n//         {showUrlWarning && <p style={{ color: 'red' }}>Please enter a valid URL.</p>}\n\n//         <button type=\"button\" className=\"next action-button\" onClick={handleStart}>\n//         Extract\n//         </button>\n\n//         </Fieldset>\n//         <Fieldset style={{ display: activeFieldset === 2 ? 'block' : 'none' }}>\n//         <h2 className=\"fs-title\">EXTRACTED URLS</h2>\n//         <div className=\"urls\">\n//         <pre ref={preRef} style={{ whiteSpace: 'pre-wrap', wordWrap: 'break-word' }}>\n//               {generatedUrls}\n//             </pre>\n//         </div>\n\n//         <button type=\"button\" className=\"previous action-button\" onClick={handlePrevious} >\n//         Previous\n//         </button>\n//         <button type=\"button\" className=\"next action-button\"  onClick={downloadPDF}\n//            >\n//         Download\n//         </button>\n//         <button\n//           type=\"button\"\n//           className=\"next action-button\"\n//           onClick={handleNext}\n//         >\n//         Next\n//         </button>\n//         </Fieldset>\n//        <Fieldset style={{ display: activeFieldset === 3 ? 'block' : 'none' }}>\n//        <h2 className=\"fs-title\">SCRAPING STAGE</h2>\n//         <h3 className=\"fs-subtitle\">Enter the URL and the selector that you want to scrape</h3>\n//         <input\n//         type=\"text\"\n//         value={urls}\n//         placeholder=\"Enter URL to scrape\"\n//         onChange={(e) => {\n//         setUrls(e.target.value);\n//         setShowUrlWarning(!isUrlValid(e.target.value));\n//         }}\n//       />\n//         <input type=\"text\" placeholder=\"Selectors\" value={selectors} onChange={(e) => setSelectors(e.target.value)} />\n//         {showUrlWarning && <p style={{ color: 'red' }}>Please enter a valid URL.</p>}\n//         <button type=\"button\" className=\"previous action-button\" onClick={handlePrevious} >\n//         Previous\n//         </button>\n//         <button\n//         type=\"submit\"\n//         className=\"submit action-button\"\n//         onClick={handleSubmit2}\n//         disabled={!urls || !selectors || showUrlWarning}>\n//         Submit\n//         </button>\n//         </Fieldset> \n\n//         <Fieldset style={{ display: activeFieldset === 4 ? 'block' : 'none' }}>\n//         <h2 className=\"fs-title\">EXTRACTED DATA</h2>\n//         <div className=\"result\">\n//           <pre ref={preRef}>{output}</pre>\n//         </div>\n//         <button type=\"button\" className=\"previous action-button\" onClick={handlePrevious}>\n//           Previous\n//         </button>\n//         <button\n//           type=\"button\"\n//           className=\"next action-button\"\n//           onClick={handleDownloadPDF}\n//             disabled={!output.trim()}\n//         >\n//           Download\n//         </button>\n//       </Fieldset>\n\n//     </form>\n//     </div>\n\n//   );\n// };\n\n// export default ScraperForm;\n\n// this is the backend code:\n\n// const express = require('express');\n// const bodyParser = require('body-parser');\n// const request = require('request-promise');\n// const cheerio = require('cheerio');\n// const axios = require('axios');\n// const fs = require('fs');\n// const Json2csvParser = require('json2csv').Parser;\n// const cors = require('cors');\n// const path = require('path');\n\n// const app = express();\n// const port = 5060;\n\n// app.use(bodyParser.json());\n// app.use(cors());\n\n// app.get('/', (req, res) => {\n//   res.send('Hello, this is the root!');\n// });\n\n// app.post('/scraper', async (req, res) => {\n//   const { url } = req.body;\n\n//   try {\n//     const response = await request({\n//       uri: url.trim(),\n//       gzip: true,\n//     });\n\n//     let $ = cheerio.load(response);\n\n//     let foundUrls = [];\n\n//     $('a').each((index, element) => {\n//       const href = $(element).attr('href');\n//       if (href && href.startsWith('http')) {\n//         foundUrls.push(href);\n//       }\n//     });\n\n//     fs.writeFileSync('./list.txt', foundUrls.join('\\n'), 'utf-8');\n\n//     res.json({ urls: foundUrls });\n//     console.log(foundUrls);\n//   } catch (error) {\n//     console.error('Error scraping URL:', error);\n//     res.status(500).json({ error: 'Internal Server Error' });\n//   }\n// });\n\n// app.post('/scrape', async (req, res) => {\n//   const { urls, selectors } = req.body;\n//   let pages = [];\n\n//   for (let article of urls) {\n//     const response = await request({\n//       uri: article.trim(),\n//       gzip: true,\n//     });\n\n//     let $ = cheerio.load(response);\n\n//     let pageData = {};\n\n//     selectors.forEach((selector) => {\n//       let values = [];\n//       $(selector).each((index, element) => {\n//         values.push($(element).text().trim());\n//       });\n//       pageData[selector] = values;\n//     });\n\n//     pages.push(pageData);\n//   }\n\n//   fs.writeFileSync('./data.json', JSON.stringify(pages), 'utf-8');\n\n//   const tableString = getTableString(pages);\n//   const outputPath = './output.txt';\n//   fs.writeFileSync(outputPath, tableString, 'utf-8');\n\n//   res.json({ tableString, pages });\n\n//   const fields = selectors;\n//   const json2csvParser = new Json2csvParser({ fields });\n//   const csv = json2csvParser.parse(pages);\n//   console.log(csv);\n\n//   console.table(pages);\n// });\n\n// function getTableString(pages) {\n//   let tableString = '';\n//   pages.forEach((page) => {\n//     for (let key in page) {\n//       tableString += `\\n ${key}: \\n \\n  ${page[key].join('\\n')}\\n`;\n\n//     }\n//     tableString += '\\n'.repeat(3);\n//   });\n//   return tableString;\n// }\n\n// app.listen(port, () => {\n//   console.log(`Server is running on http://localhost:${port}`);\n// });\n\n// modify the code such that the second Fielset displays the content of list.txt\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["React","ScraperForm","jsxDEV","_jsxDEV","App","className","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["C:/Users/PC/tryg/front/src/App.js"],"sourcesContent":["import React from 'react';\nimport ScraperForm from './components/ScraperForm';\n\nfunction App() {\n  return (\n    <div className=\"App\">\n      <ScraperForm />\n    </div>\n  );\n}\n\nexport default App;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// this is the frontend code:\n\n// import React, { useState, useRef} from 'react';\n// import axios from 'axios';\n// import './form.css';\n// import * as html2pdf from 'html2pdf.js';\n\n\n// const ProgressBar = ({ activeFieldset }) => (\n//     <ul id=\"progressbar\">\n//       <li className={activeFieldset === 1 ? 'active' : ''}>URL EXTRACTION</li>\n//       <li className={activeFieldset === 2 ? 'active' : ''}>EXTRACTED URLS</li>\n//       <li className={activeFieldset === 3 ? 'active' : ''}>SCRAPING</li>\n//       <li className={activeFieldset === 4 ? 'active' : ''}>EXTRACTED DATA</li>\n//     </ul>\n//   );\n\n\n//   const Fieldset = ({ title, subtitle, children, style }) => (\n//     <fieldset style={style}>\n//       <h2 className=\"fs-title\">{title}</h2>\n//       <h3 className=\"fs-subtitle\">{subtitle}</h3>\n//       {children}\n//     </fieldset>\n//   );\n\n// const ScraperForm = () => {\n\n//     const [activeFieldset, setActiveFieldset] = useState(1);\n//     const [formData, setFormData] = useState({\n//       email: '',\n//       text2: '',\n//       text3: '',\n//     });\n\n\n//   const [urls, setUrls] = useState('');\n//   const [selectors, setSelectors] = useState('');\n//   const [output, setOutput] = useState('');\n//   const [showUrlWarning, setShowUrlWarning] = useState(false);\n\n//   const [generatedUrls, setGeneratedUrls] = useState('');\n\n//   const preRef = useRef(null);\n\n\n//   const isUrlValid = (userInput) => {\n//     const res = userInput.match(/(http(s)?:\\/\\/.)?(www\\.)?[-a-zA-Z0-9@:%._+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_+.~#?&//=]*)/g);\n//     return res !== null;\n//   };\n  \n\n\n\n\n\n//   const handleDownloadPDF = () => {\n//     const element = preRef.current; \n//     const pdfOptions = {\n//       margin: 10,\n//       filename: 'output.pdf',\n//       image: { type: 'jpeg', quality: 0.98 },\n//       html2canvas: { scale: 2 },\n//       jsPDF: { unit: 'mm', format: 'a4', orientation: 'portrait' },\n//     };\n\n//     html2pdf(element, pdfOptions);\n//   };\n\n\n\n//   const downloadPDF = async () => {\n//     const element1 = preRef.current; \n//     const pdfOptions1 = {\n//       margin: 10,\n//       filename: 'list.pdf',\n//       image: { type: 'jpeg', quality: 0.98 },\n//       html2canvas: { scale: 2 },\n//       jsPDF: { unit: 'mm', format: 'a4', orientation: 'portrait' },\n//     };\n\n//     html2pdf(element1, pdfOptions1);\n//   };\n\n\n\n\n\n//   const handleStart = async (e) => {\n//     e.preventDefault();\n\n//     try {\n//       const response = await axios.post('http://localhost:5045/scraper', { url: formData.email });\n//       setGeneratedUrls(response.data.urlContent || '');\n      \n    \n//       handleNext();\n//     } catch (error) {\n//       console.error('Error generating list of URLs:', error);\n//     }\n//   };\n\n  \n\n//   const handleInputChange = (e) => {\n//     const { name, value } = e.target;\n\n//     if (name === 'email') {\n//       setShowUrlWarning(!isUrlValid(value));\n     \n//     }\n    \n//     setFormData((prevData) => ({\n//         ...prevData,\n//         [name]: value,\n//       }));\n\n//   };\n\n//   const handleNext = () => {\n//     setActiveFieldset((prevActiveFieldset) => prevActiveFieldset + 1);\n//   };\n\n//   const handlePrevious = () => {\n//     setActiveFieldset((prevActiveFieldset) => prevActiveFieldset - 1);\n//   };\n\n\n\n\n//   const handleSubmit2 = async (e) => {\n//     e.preventDefault();\n\n \n//     try {\n//       const response = await axios.post('http://localhost:5045/scrape', {\n//         urls: urls.split(',').map((url) => url.trim()),\n//         selectors: selectors.split(',').map((selector) => selector.trim()),\n//       }, {\n//         timeout: 5000, \n//       });\n\n//       console.log(response.data + '\\n');\n\n \n//       setOutput(response.data.tableString);\n//       handleNext();\n\n//     } catch (error) {\n//       console.error('Error:', error);\n//     }\n   \n//   };\n\n//   return (\n\n//   <div>\n//     <ProgressBar activeFieldset={activeFieldset} />\n//       <form id=\"msform\" onSubmit={handleSubmit2}>\n\n//         <Fieldset style={{ display: activeFieldset === 1 ? 'block' : 'none' }}>\n//         <h2 className=\"fs-title\">Provide the Main URL</h2>\n//  \t\t    <h3 className=\"fs-subtitle\">This step will provide the list of all URLS</h3>\n//              <input\n//           type=\"text\"\n//           name=\"email\"\n//           placeholder=\"Main URL\"\n//           value={formData.email}\n//           onChange={handleInputChange}\n//         />\n//         {showUrlWarning && <p style={{ color: 'red' }}>Please enter a valid URL.</p>}\n\n        \n//         <button type=\"button\" className=\"next action-button\" onClick={handleStart}>\n//         Extract\n//         </button>\n        \n   \n//         </Fieldset>\n//         <Fieldset style={{ display: activeFieldset === 2 ? 'block' : 'none' }}>\n//         <h2 className=\"fs-title\">EXTRACTED URLS</h2>\n//         <div className=\"urls\">\n//         <pre ref={preRef} style={{ whiteSpace: 'pre-wrap', wordWrap: 'break-word' }}>\n//               {generatedUrls}\n//             </pre>\n//         </div>\n\n//         <button type=\"button\" className=\"previous action-button\" onClick={handlePrevious} >\n//         Previous\n//         </button>\n//         <button type=\"button\" className=\"next action-button\"  onClick={downloadPDF}\n//            >\n//         Download\n//         </button>\n//         <button\n//           type=\"button\"\n//           className=\"next action-button\"\n//           onClick={handleNext}\n//         >\n//         Next\n//         </button>\n//         </Fieldset>\n//        <Fieldset style={{ display: activeFieldset === 3 ? 'block' : 'none' }}>\n//        <h2 className=\"fs-title\">SCRAPING STAGE</h2>\n//         <h3 className=\"fs-subtitle\">Enter the URL and the selector that you want to scrape</h3>\n//         <input\n//         type=\"text\"\n//         value={urls}\n//         placeholder=\"Enter URL to scrape\"\n//         onChange={(e) => {\n//         setUrls(e.target.value);\n//         setShowUrlWarning(!isUrlValid(e.target.value));\n//         }}\n//       />\n//         <input type=\"text\" placeholder=\"Selectors\" value={selectors} onChange={(e) => setSelectors(e.target.value)} />\n//         {showUrlWarning && <p style={{ color: 'red' }}>Please enter a valid URL.</p>}\n//         <button type=\"button\" className=\"previous action-button\" onClick={handlePrevious} >\n//         Previous\n//         </button>\n//         <button\n//         type=\"submit\"\n//         className=\"submit action-button\"\n//         onClick={handleSubmit2}\n//         disabled={!urls || !selectors || showUrlWarning}>\n//         Submit\n//         </button>\n//         </Fieldset> \n\n     \n//         <Fieldset style={{ display: activeFieldset === 4 ? 'block' : 'none' }}>\n//         <h2 className=\"fs-title\">EXTRACTED DATA</h2>\n//         <div className=\"result\">\n//           <pre ref={preRef}>{output}</pre>\n//         </div>\n//         <button type=\"button\" className=\"previous action-button\" onClick={handlePrevious}>\n//           Previous\n//         </button>\n//         <button\n//           type=\"button\"\n//           className=\"next action-button\"\n//           onClick={handleDownloadPDF}\n//             disabled={!output.trim()}\n//         >\n//           Download\n//         </button>\n//       </Fieldset>\n\n      \n\n//     </form>\n//     </div>\n\n//   );\n// };\n\n// export default ScraperForm;\n\n\n\n\n\n\n\n\n// this is the backend code:\n\n\n// const express = require('express');\n// const bodyParser = require('body-parser');\n// const request = require('request-promise');\n// const cheerio = require('cheerio');\n// const axios = require('axios');\n// const fs = require('fs');\n// const Json2csvParser = require('json2csv').Parser;\n// const cors = require('cors');\n// const path = require('path');\n\n// const app = express();\n// const port = 5060;\n\n// app.use(bodyParser.json());\n// app.use(cors());\n\n// app.get('/', (req, res) => {\n//   res.send('Hello, this is the root!');\n// });\n\n\n\n\n\n\n\n\n\n\n// app.post('/scraper', async (req, res) => {\n//   const { url } = req.body;\n\n//   try {\n//     const response = await request({\n//       uri: url.trim(),\n//       gzip: true,\n//     });\n\n//     let $ = cheerio.load(response);\n\n//     let foundUrls = [];\n\n//     $('a').each((index, element) => {\n//       const href = $(element).attr('href');\n//       if (href && href.startsWith('http')) {\n//         foundUrls.push(href);\n//       }\n//     });\n\n//     fs.writeFileSync('./list.txt', foundUrls.join('\\n'), 'utf-8');\n\n//     res.json({ urls: foundUrls });\n//     console.log(foundUrls);\n//   } catch (error) {\n//     console.error('Error scraping URL:', error);\n//     res.status(500).json({ error: 'Internal Server Error' });\n//   }\n// });\n\n\n\n\n\n// app.post('/scrape', async (req, res) => {\n//   const { urls, selectors } = req.body;\n//   let pages = [];\n\n//   for (let article of urls) {\n//     const response = await request({\n//       uri: article.trim(),\n//       gzip: true,\n//     });\n\n//     let $ = cheerio.load(response);\n\n//     let pageData = {};\n\n//     selectors.forEach((selector) => {\n//       let values = [];\n//       $(selector).each((index, element) => {\n//         values.push($(element).text().trim());\n//       });\n//       pageData[selector] = values;\n//     });\n\n//     pages.push(pageData);\n//   }\n   \n\n//   fs.writeFileSync('./data.json', JSON.stringify(pages), 'utf-8');\n\n//   const tableString = getTableString(pages);\n//   const outputPath = './output.txt';\n//   fs.writeFileSync(outputPath, tableString, 'utf-8');\n\n//   res.json({ tableString, pages });\n\n//   const fields = selectors;\n//   const json2csvParser = new Json2csvParser({ fields });\n//   const csv = json2csvParser.parse(pages);\n//   console.log(csv);\n\n//   console.table(pages);\n// });\n\n\n// function getTableString(pages) {\n//   let tableString = '';\n//   pages.forEach((page) => {\n//     for (let key in page) {\n//       tableString += `\\n ${key}: \\n \\n  ${page[key].join('\\n')}\\n`;\n      \n\n//     }\n//     tableString += '\\n'.repeat(3);\n//   });\n//   return tableString;\n// }\n\n// app.listen(port, () => {\n//   console.log(`Server is running on http://localhost:${port}`);\n// });\n\n\n\n\n\n\n\n\n// modify the code such that the second Fielset displays the content of list.txt"],"mappings":";AAAA,OAAOA,KAAK,MAAM,OAAO;AACzB,OAAOC,WAAW,MAAM,0BAA0B;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEnD,SAASC,GAAGA,CAAA,EAAG;EACb,oBACED,OAAA;IAAKE,SAAS,EAAC,KAAK;IAAAC,QAAA,eAClBH,OAAA,CAACF,WAAW;MAAAM,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACZ,CAAC;AAEV;AAACC,EAAA,GANQP,GAAG;AAQZ,eAAeA,GAAG;;AAuBlB;;AAEA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;;AAEA;;AAEA;;AAGA;AACA;AACA;AACA;;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAMA;AACA;;AAEA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;;AAIA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAKA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAGA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAIA;AACA;;AAEA;AACA;;AAEA;;AASA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAWA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAMA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAGA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAGA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AASA;AAAA,IAAAO,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}